# -*- coding: utf-8 -*-
"""bangkit w05 winequality

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EMIcolKu065Tj_HghZFkMadiuGeVZ3Yl

# Preparation
"""

# Install TF docs
!pip install -q git+https://github.com/tensorflow/docs

#@title Import statements

import tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)

import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

#@title (Misc) GDrive integration
import os
from google.colab import drive
drive.mount('/content/gdrive')

"""# Read dataset from CSV file"""

url = 'https://raw.githubusercontent.com/imiro/bangkit-w05-winequality/master/datasets/winequality-red.csv'
df = pd.read_csv(url)

"""# Dataset characteristics"""

#@title Import plotting functions

import matplotlib.pyplot as plt
import seaborn as sns
import pandas.util.testing as tm
from collections import Counter

df.head(10)

"""Here we explore what our dataset has to offer."""

df.info()

df.shape

df.columns

df['quality'].value_counts(sort=False)

sns.countplot(x='quality', data=df)

sns.pairplot(df)

"""# Data Prep

## Group quality to 3 categories

To simplify our problem, we want to divide 0-10 quality scale into 3 rating categories: `low`, `moderate/average` and `high/good` quality. These categories should be more practical for real-world use.

We determine that:
- wine quality of `0 - 4` belongs to `low` rating (label: `0`)
- wine quality of `5 - 6` belongs to `moderate/average` rating (label: `1`)
- wine quality of `>= 7` belongs to `high/good` rating (label: `2`)
"""

# divide quality to rating
# 0 < q < 5: 0; 5 <= q < 7: 1; q >= 7: 2;

df['Rating'] = df['quality'].map(lambda x: 0 if x < 5 else 1 if x < 7 else 2)

df['Rating'].value_counts()

df.describe().transpose()

dataset = df.copy()
dataset.pop("quality")

"""## Create test data

We don't have test data available as is from the source, so we have to create it from the data pool.

We decided to train on 80% of the data, and make the rest 20% as the test data.

To avoid bias, we divide the train and test data with random sampling.
"""

train_dataset = dataset.sample(frac=0.8,random_state=0)
test_dataset = dataset.drop(train_dataset.index)

train_dataset

"""Statistics of the training set.

We will use values from this stats (mean, std) to normalize the data.
"""

train_stats = train_dataset.describe()
train_stats.pop("Rating")
train_stats = train_stats.transpose()
train_stats

"""## Separate label and features"""

train_labels = train_dataset.pop('Rating')
test_labels = test_dataset.pop('Rating')

"""## Normalize values

On our attempt to see our dataset characteristics earlier, we see that range of the data varies.

For example, values of `fixed acidity` ranges from `4.6 - 15.9`, while `total sulfur dioxide` has a range of `6 - 62`. Meanwhile, `pH` values only range from `2.74` to `4.01`.

That this can cause  issues when training the model. Therefore, we convert each value of the features to its Z-score.
"""

def norm(x):
  return (x - train_stats['mean']) / train_stats['std']
normed_train_data = norm(train_dataset)
normed_test_data = norm(test_dataset)

normed_train_data.describe().transpose()

"""# Define the function that builds model"""

def build_model(my_learning_rate):
  model = keras.Sequential([
    layers.Flatten(input_shape=[(len(train_dataset.keys()))]),
    layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    layers.Dense(3),
  ])

  optimizer = tf.keras.optimizers.Adam(learning_rate=my_learning_rate)

  model.compile(optimizer=optimizer,
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
  return model

"""# Build and train the model"""

# Hyperparameters
EPOCHS = 100
learning_rate = 0.001

model = build_model(learning_rate)
print(model.summary())

checkpoint_path = "/content/gdrive/My Drive/Trained_Models/wine_binary_quality/wine_binary_quality.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
history = model.fit(
  normed_train_data, train_labels,
  epochs=EPOCHS, 
  validation_split = 0.2, 
  )

"""# Evaluate the model"""

# Evaluate model with test data

test_loss, test_acc = model.evaluate(normed_test_data, test_labels, verbose=2)
print('Test accuracy:', test_acc)

"""# Export model to GDrive"""

probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])

predictions = probability_model.predict(
    normed_test_data)
# predictions

# i = len(predictions)
# np.argmax(predictions[i-1])

checkpoint_path = "/content/gdrive/My Drive/Trained_Models/wine_classifier/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

model.save_weights('/content/gdrive/My Drive/Trained_Models/wine_classifier/wine_quality_model')

model_save_name = 'wine_classifier'
save_model_path = '/content/gdrive/My Drive/Trained_Models/wine_classifier'

model.save(save_model_path)

model.save('/content/gdrive/My Drive/Trained_Models/wine_classifier/wine_classifier.h5')

converter = tf.lite.TFLiteConverter.from_saved_model(save_model_path)
tflite_model = converter.convert()
open("/content/gdrive/My Drive/Trained_Models/wine_classifier/wine_classifier.tflite", "wb").write(tflite_model)